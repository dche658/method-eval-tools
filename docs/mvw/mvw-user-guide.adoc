= Method Verification Workbook User Guide
:imagesdir: ./images
:stylesdir: ./style
:toc: left
:toclevels: 3
:stem:

== Introduction

The method verification workbook has been developed to assist laboratories to document and
analyse the results of their method verification studies, as well as any decsions about 
the acceptability of the methods being evaluated against stipulated acceptance criteria.

A basic understanding of Microsoft Excel is needed to use the verification worksheet and the workbook has been designed to be used with the Method Evaluation Tools Excel Add-in

== Workbook layout

The verification workbook consists of the following worksheet tabs:

1. Template – This is the main worksheet and should be renamed to the measurand being evaluated. 
The sheet may be copied so multiple analytes can be included within the one workbook. The sheet includes 
several sections.
.. Summary: That stipulates the measurand including the specific matrix being evaluated; the device
being used; comments regarding the evaluation; and decsion as to the acceptability of the method.
.. Comparison using patient samples.
.. Trueness assessment with standard materials: Usually for assessing trueness if an existing method is 
not available or the reference and candidate methods produce results that are significantly different.
.. Precision: For evaluating imprecision of the assay.
.. Reference Intervals: For verifying a reference interval using the method of CLSI-EP28
.. LOB, LOD, LOQ: For evaluating the detection capability of the assay.
2. Example: Same as the template tab but containing some example data.
3. APS: Analytical performance specifications for the assays along with information on biological variation.
4. Tables: Various look up tables used by the spreadsheet.

NOTE: The template is password protected to prevent inadvertant corruption of the formulas. However,
if users wish to customise the worksheets the password to unlock the sheets is simply 'password'.				

Data fields have been colour-coded in some areas to assist in entering information, as follows:

* White background: Cells for entering information.
* Pale green background: These are locked cells and cannot be edited without disabling write protection.

== Before you start

*Read this work instruction in its entirety before using the template.*

*It is recommended that a fresh version of the workbook from the 
https://metools.chesher.id.au/assets/mvw.xlsx[repository] is used.*

Open Microsoft Excel and ensure you have the Method Evaluation Tools Excel Add-in 
installed. It is preferable to do this before you open the method
evaluation workbook as the password protection of the template may 
prevent you from accessing the Add-ins menu.

From the Microsoft Excel menu select *Home &gt; Add-ins &gt; More Add-ins*

If you have previously installed the add-in, go to the *MY ADD-INS* tab
and add your add-in. Alternatively, search for the method evaluation tools 
add-in in the *Store* tab.

The APS worksheet containing the analytical performance specifications is not 
password protected so that users may update it with their chosen specifications 
as required.

image::refresh-aps-data.png[float=right]
A default set is provided and are sourced from an APS database available 
https://aps.chesher.id.au/[here]. 
Refresh the APS table by selecting the APS worksheet. Then from the Data ribbon 
select the “Refresh All” icon. This will cause the worksheet to pull the APS 
information from the database. You must do this before making any changes, as 
the update will overwrite any changes you have made.

If the test you require cannot be found or you believe the 
information needs to be updated contact the custodian of the APS database to make these 
changes. The minimum information required is the measurand (analyte, matrix); units of 
measure; analytical performance specification in reportable units (absolute value), as a 
percentage (relative), and the cut-off. If known, also provide the within 
subject and between subject biological variation for the measurand.

== Setup
Select the analyte and the matrix from the dropdown lists provided.

image::dropdown-analyte.png[] 
image::dropdown-sample-type.png[]

If the add-in taskpane is not already open select *Home &gt; Basic Tools* from the 
Excel menu.

image::addin-start.png[]

Scroll down and click on the *Load Range Defaults* section. Then click on the 
Load Defaults button to import the cell ranges used by the template into
the add-in.

image::addin-load-defaults.png[]

== Trueness verification

Trueness may be assessed by either direct patient comparison to an existing method, and or 
comparison to established values for standard reference materials or material from an 
external quality assurance program.

Selection of the most appropriate method for evaluating trueness should be made according to 
your method verification policy.

=== Assessment of trueness using comparison of results with patient samples

To ensure a robust assessment, patient samples should be distributed evenly over the entire 
measuring range of the assay.

Calibrate as specified by the manufacturer. If the manufacturer stated that the precision 
data were generated over multiple calibration cycles, then the operator may choose to 
recalibrate during the experiment.

Always run the daily QC material normally used in each run. Reject or accept run based on 
normal laboratory criteria. However, these values are not recorded on the Method Verification 
Workbook.

Data should be recorded on the comparison table. If more than one analyte is to be assessed 
the user may rename the worksheet name to include the analyte name. 

For a primary verification study, it is recommended that at least 40 patient samples 
covering the analytical measuring range are included and analysed in duplicate using both 
the reference and proposed methods.

For a secondary verification study, it is recommended that at least 20 patient samples 
covering the analytical measuring range are included.

If frozen aliquots are used, they should be thawed once and analysed together.

Ideally, sample sets should be spaced out over several days to allow for between-day 
variability of instrument performance and environmental conditions.

Some patient samples may show large discrepancies between the two methods due to differences 
between the two measurement procedures. Such discrepancies should be reproducible if they 
are to be excluded from statistical analyses.

Enter all patient sample data acquired into the comparison table. Only numeric values 
should be used. Do not use results that are below the lower limit of quantitation. Ensure 
there are no gaps between rows of data. 

IMPORTANT: For each row, specify whether to *INCLUDE* or *EXCLUDE* the data points. 
*THIS ACTION IS ESSENTIAL FOR DATA ANALYSIS.*
Only data points labeled with INCLUDE will be analysed further.

image::comparison-data.png[]

If data is excluded, then additional samples may need to be run to meet the recommended 
minimum sample size. Do this NOW before proceeding further, that is, enter the additional 
data, and apply the inclusion/exclusion criteria to the additional results.

=== Comparison analysis

Choose your preferred method of linear regression analysis. The method
of Passing and Bablok is selected by default.

If the SD over the analytical range is thought to be constant, then 
Deming regression may be used. Alternatively, if the CV over the
analytical range is thought be roughly constant, then Weighted Deming 
regression may be used.

If Deming or Weighted Deming regression is used and samples have been analysed 
in duplicate, then select whether to use the calculated error ratio or the user 
defined error ratio below (default is 1.0). The error ratio is the SD or CV of 
the proposed method divided by the SD or CV of the reference method.

Select the method for determining confidence intervals. The default method for 
Deming and Weighted Deming regression is a jackknife procedure. The default 
method for Passing Bablok regression is to use the appropriate quantiles. 
The bootstrap method can be used for all the regression procedures.

Select the difference plot type. If the ratio of the highest concentration to the lowest concentration in your dataset is &gt; 5, the a *Relative* difference
plot is suggested. This is the default selection.

Once the parameters have been selected, click on the *Run Regression* button to 
perform the calculation and display the charts.

==== Bland Altman plot

The limits of agreement should be within the allowable limits of performance.

== Evaluation of trueness using EQA material or similar

This form of verification should be used if:

. the two methods are substantially different. For example, if the test method 
uses a different analytical principle to the reference method, or
. the manufacturer has not provided relevant bias information, or
. an EQA program exists that can be used for trueness verification.
							
Calibrate as specified by the manufacturer.

Always run the daily QC material normally used in each run. Reject or accept 
run based on normal laboratory criteria. However, these values are not recorded 
on the Method Verification Workbook.

Enter the required information about the EQA material into the relevant fields i.e.				

.. Trueness verification based on RCPAQAP material
.. Trueness verification based on other reference materials

Analyse each EQA material in replicate (preferred). Singlicate measurements are 
accepted by the worksheet.  Enter results into designated fields of the 
standard materials section.

The spreadsheet automatically reports the "Trueness Verification Result" as a 
"PASS" or "FAIL".

If the "Trueness Verification Result" is "PASS" then the test method generates 
results that are within acceptable limits of the designated reference method. 
Trueness is verified for the proposed method.

If the "Trueness Verification Result" is "FAIL" then the proposed method 
generates results that are not always identical to the designated reference 
method. Trueness is not verified for the proposed method for all data points.
						
If trueness is not verified, then the acceptability of the assay for the 
laboratory's needs should be reviewed further and/or the manufacturer should be 
contacted.

== Concordance

When undertaking comparisons of patient materials there may be circumstances 
when the two methods are not expected to provide identical results but can be 
interpreted against one or more decision limits. For example, troponin assays 
where the antibodies are assay specific and react with circulating forms in 
different ways. In this situation, the patient comparison sheet can be used to
assess concordance.

Complete the patient comparison study in the same way as previously described.

Expand the *Cohen's Kappa* section of the add-in and enter the diagnostic 
cutoffs for the reference method and proposed method. The diagnostic cutoff’s 
need not be the same value but the number of cutoffs for the reference method 
and proposed method must be the same.

Click on the *Run Regression* button to perform the calculation and display
the results in the worksheet.

There is a place in the worksheet for recording the diagnostic cutoffs, but
these are not used by the add-in. They are included for the purpose of
documenting the thresholds used.

== Precision verification 

The purpose of this evaluation is to assess whether the assay meets the 
laboratory’s requirements for imprecision. Comparisons are calculated against:

. The manufacturer’s claims for repeatability (within run)
and within laboratory (total) imprecision. These claims are generally available 
from the information for use (IFU) provided by the manufacturer. The claim may 
need to be interpolated from that in the IFU dependent on the levels at which 
the precision experiment is conducted.
. Analytical performance specifications calculated from the known biological 
variation for the analyte. APS limits may be set at optimal, desirable, or 
minimal requirements.
. Calculation of the assay capability. 

The QC material to control the assay during the imprecision assessment should
be different/independent to that used to undertake the imprecision assessment. 
The manufacturer's own QC material would generally be expected to provide the 
best estimate if precision. However, if this is not available then alternative 
QC material or patient pool may be used. 

Calibrate as specified by the manufacturer. Always run the daily QC material 
normally used in each run. Reject or accept run based on normal laboratory 
criteria. However, these values are not recorded in the Method Verification 
Workbook. 

Enter the required information about the QC material in the designated fields.

For a primary verification experiment, analyse 5 replicates each day over five
days for at least two concentrations.

Enter results into the designated fields in the spreadsheet.

Click on the *Grubb's Test for Outliers* button in the precision section
of the add-in. If outliers are found, a notification will be given to that
fact and the out lying value will be highlighted in yellow.

If an outlier is found, the precision results for that day should be excluded
the the study for that day should be repeated.

If no outliers are detected, ensure the claimed imprecision information has
been entered and then click on the *Run* button.

=== Comparison against the manufacturer’s imprecision claims 

The add-in calculates the repeatability and within laboratory (total) 
imprecision and the workbook then uses this information to calculate the
verification limits.

The worksheet will report the results of the repeatability and within 
laboratory (total) imprecision verifications as either a "PASS" or 'FAIL".

If the measured repeatability is less than or equal to the calculated
repeatability verification limit, then the manufacturer's claims are verified.

If the measured within laboratory precision is less than or equal to the 
calculated within laboratory verification limit, then the manufacturer's claims are verified. 

If either or both are not verified, then the acceptability of the assay for the 
laboratory's needs should be reviewed further and/or the manufacturer may be 
contacted.

Note, just because the observed precision does not meet the
manufacturers representative data in the IFU does not necessarily mean it is 
not fit for purpose. The representative data in the IFU are generally derived 
under optimal conditions and may not necessarily be achievable. Consideration 
should be given to comparing against other performance specifications, including those based on biological variation. If this is replacing an existing
assay, it may be reasonable to compare to performance with the current method. 

=== Comparison against laboratory acceptable performance limits based on biological variation. 

This form of verification should be used if the manufacturer-provided 
imprecision information is not available, and the laboratory has biological 
variation data that enables performance specifications to be calculated. 

The biological variation data is retrieved from the APS database. 

If biological variation information is available but not within the APS table, 
then contact the APS custodian to have the information updated. Select the 
quality requirement as optimal, desirable, or minimal.

Set the level of significance (alpha) to be evaluated. The default is 5% or 
0.05. 

The spreadsheet will automatically assess whether the within laboratory 
imprecision is within the APS and report this as PASS or FAIL.

=== Assay Capability
 
The spreadsheet will automatically calculate the capability at
each concentration where the capability is the RCPA QAP APS divided by the 
within laboratory imprecision.

This is generally used to define the quality control procedures to be applied 
to the assay but can also be of use when the assessment of imprecision has not 
met the manufacturers claim. If the capability is greater than 6, the assay is 
still able to easily meet the performance specification and is likely to be fit 
for purpose.

If the capability is less than 3 the assay is not able to meet the performance 
specification and alternative procedures may need to be considered.

== Reference intervals

If the proposed method is replacing an existing method and there is good 
agreement between the two methods, then the existing reference interval
may be used.

If common reference intervals are being used then assess the difference between
methods against the maximum desirable bias. If the difference
between methods exceeds this, then a different reference interval may be 
required.

If the manufacturer has provided a reference interval or an appropriate one can 
be found from the literature, then the reference interval should be verified on 
a population of reference individuals.

Start with 20 individuals for each partition that is required. (eg. age or 
gender). Exclude any obvious outliers and recruit additional individuals if 
necessary to get the minimum number of 20 individuals. If more than 2 
individuals have results outside the reference interval for that partition, 
then collect another 20 individuals. If the number of outliers is no more than
that expected for that population, the reference interval is verified. 
Otherwise, a different reference interval may be required, or a formal 
reference interval study undertaken. 

The evaluation is based on the cumulative binomial distribution function with 
up to k outliers in n trials (number of subjects) where the probability of an 
outlier is 0.05. This assumes the reference interval is designed to cover 95% 
of the population.

== Detection capability

A common verification approach is used for each of the detection capability claims. A small number of
samples are tested in replicate over multiple days using a single reagent lot and a single
instrument system. The proportion of measurement results that are consistent with the respective
claim is calculated and compared to the appropriate boundary value, in order to determine the
outcome of the verification. If the observed proportion is less than the boundary value, one may
conclude that the observed results are not consistent with the claim.

=== Limit of blank

verification Analyse a suitable number of blank samples, with sufficient replicates and days to
ensure at least 20 blank replicates are performed over the days and samples. There does not need to
be an equal number of replicates for each sample for all days, but it is desirable. 

Prepare sufficient aliquots of all blank samples to complete the planned testing. Ensure that extra
aliquots are provided to accommodate possible testing errors or processing upsets.

Each testing day, process the designated number of replicate tests for each sample according 
to the processing plan. 

Review the measurement results each testing day to check for possible processing errors or
missing results. Identify potential outliers and assignable causes for them. Outliers arising from
such assignable causes - aside from analytical errors of the measurement procedure itself - may be
retested and substituted into the data, ideally on the same testing day. Any such retests must be
documented along with the original test results. Presence of more than two such outliers identified
for assignable causes across all blank sample results is reason to reject and repeat the study.

Ensure that sufficient measurement results are available at the end of testing to start data
analysis.

A minimum of 20 total blank sample results are required.

Select the LOQ section for the workbook

Enter the claimed limit of blank. 

Enter the values of the replicates in the table provided. 

The spreadsheet will calculate a limit of blank from the data. However, the verification
is performed using a non-parametric assessment of the proportion of samples below the limit of
blank.

=== Limit of detection

Verify the claimed LoB as outlined above. If the claim is not met, then undertake a study to 
determine the LoB.

Select three samples with concentrations near the limit of detection. 

Prepare sufficient aliquots of all low level samples to complete the
planned testing. Ensure that extra aliquots are provided to accommodate possible testing errors or
processing upsets.

Analyse the three samples, with sufficient replicates and days to ensure at
least 20 replicates are performed over the days and samples. There does not need to be an equal
number of replicates for each sample for all days, but it is desirable.

Review the measurement results each testing day to check for possible processing errors or 
missing results. Identify potential outliers and assignable causes for them. Outliers arising from such assignable causes -
aside from analytical errors of the measurement procedure itself - may be retested and substituted
into the data, ideally on the same testing day. Any such retests must be documented, along with the
original test results. Presence of more than two such outliers identified with no assignable causes
across all low level sample results is reason to reject and repeat the study.

Ensure that a sufficient number of measurement results are available at the end of testing to start data
analysis. A minimum of 20 total low level sample results are required.

Select the LOQ tab for the Excel workbook Within the LoD section of the worksheet, enter the 
limit of blank that was verified or determined.

Enter the replicate data for the low level samples in the table provided.

The spreadsheet will calculate a limit of detection from the data. However, the verification is
performed using a non-parametric assessment of the proportion of samples below the limit of
detection.

=== Limit of quantitation

Select three samples with concentrations near the limit of detection.

Decide on the number of days and replicates per day to be performed for
each sample to ensure at least 20 replicates are available for data analysis.

Prepare sufficient aliquots of all samples to complete the planned testing. Ensure that extra 
aliquots are provided to accommodate possible testing errors or processing upsets.

Each testing day, process the designated number of replicate tests for each sample according 
to the processing plan.

Review the measurement results each testing day to check for possible processing errors or 
missing results. Identify potential outliers and assignable causes for them. Outliers arising
from such assignable causes -
aside from analytical errors of the measurement procedure itself - may be retested and substituted
into the data, ideally on the same testing day. Any such retests must be documented, along with the
original test results. Presence of more than two such outliers identified for assignable causes
across all results is reason to reject and repeat the study.

Ensure that a sufficient number of measurement results are available at the end of testing to 
start data analysis. A minimum of 20 total sample results are required.

Select the LOQ tab for the Excel workbook

Within the LoQ section of the worksheet, enter the claimed limit of quantitation.

Enter the data for each of the samples in the table provided.

Verification is performed using a non-parametric assessment of the
proportion of replicates with deviations from the mean that are less than the total error
specification.

